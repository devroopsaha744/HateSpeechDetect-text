{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8503427,"sourceType":"datasetVersion","datasetId":5075104}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"name":"Hatespeech Finetuning LLM","provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3a3b4f877ce545f6a7e666310344154c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a864d63aed64087b938a7cd00163eee","IPY_MODEL_6fb0cc835bd645cab97cd5e5b5d72061","IPY_MODEL_901c0f84a73b4fb3bb8e3de1c80798f5"],"layout":"IPY_MODEL_b2470f2a2191423cab3231c187a448bb"}},"6a864d63aed64087b938a7cd00163eee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_241bdc8e67664711b1f4f6fc704ec863","placeholder":"​","style":"IPY_MODEL_592837a5f3274a51a932a3ab329e5817","value":"Loading checkpoint shards: 100%"}},"6fb0cc835bd645cab97cd5e5b5d72061":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6df936f62eff46dc9663c8fb18fdec60","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57b0be4c97eb48d4b8b20509dcbdae4d","value":2}},"901c0f84a73b4fb3bb8e3de1c80798f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ae5582031e74436bd076dcafa2ed26a","placeholder":"​","style":"IPY_MODEL_9e62eac2ac6c48cba6a9987d93df135f","value":" 2/2 [00:08&lt;00:00,  3.62s/it]"}},"b2470f2a2191423cab3231c187a448bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"241bdc8e67664711b1f4f6fc704ec863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"592837a5f3274a51a932a3ab329e5817":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6df936f62eff46dc9663c8fb18fdec60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57b0be4c97eb48d4b8b20509dcbdae4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ae5582031e74436bd076dcafa2ed26a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e62eac2ac6c48cba6a9987d93df135f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\n\nimport os\nimport sys\nfrom tempfile import NamedTemporaryFile\nfrom urllib.request import urlopen\nfrom urllib.parse import unquote, urlparse\nfrom urllib.error import HTTPError\nfrom zipfile import ZipFile\nimport tarfile\nimport shutil\n\nCHUNK_SIZE = 40960\nDATA_SOURCE_MAPPING = 'hatespeech-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5075104%2F8503427%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240531%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240531T064543Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D69e38690ab33e95c3c8f7d90998ed56c49bc77e15d3fbc3332096c4f8edf03f4898603800a7c084c109048544ca7f38058ccef0b237522f9869119512bcfe04e2bbb423341a551719d23752e6bba33186b4b18d33359702f05d91eb036542694d93ca2b6636fbceb4e4615eabf64f17567e33c6435afa04da9bc2f76a2e46bee4116b0502d5ce3a0b1ce9beac18e29f1ef75d9e846ef3553aea0bcc6d85dfb9bc260cfaacd7e25b32ee1ee6c29393b8c200e8cce4bacf0e79061c5a34795b3c45d3e4385c193cb0fe880f89c6e120ee6091f955cae74064e325ef6aeb1cd0333e8e1af1203cb08a34443bd7173505dc031e16ef9b83b2c55bae2b225c25827e1'\n\nKAGGLE_INPUT_PATH='/kaggle/input'\nKAGGLE_WORKING_PATH='/kaggle/working'\nKAGGLE_SYMLINK='kaggle'\n\n!umount /kaggle/input/ 2> /dev/null\nshutil.rmtree('/kaggle/input', ignore_errors=True)\nos.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\nos.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n\ntry:\n  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\nexcept FileExistsError:\n  pass\ntry:\n  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\nexcept FileExistsError:\n  pass\n\nfor data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n    directory, download_url_encoded = data_source_mapping.split(':')\n    download_url = unquote(download_url_encoded)\n    filename = urlparse(download_url).path\n    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n    try:\n        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n            total_length = fileres.headers['content-length']\n            print(f'Downloading {directory}, {total_length} bytes compressed')\n            dl = 0\n            data = fileres.read(CHUNK_SIZE)\n            while len(data) > 0:\n                dl += len(data)\n                tfile.write(data)\n                done = int(50 * dl / int(total_length))\n                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n                sys.stdout.flush()\n                data = fileres.read(CHUNK_SIZE)\n            if filename.endswith('.zip'):\n              with ZipFile(tfile) as zfile:\n                zfile.extractall(destination_path)\n            else:\n              with tarfile.open(tfile.name) as tarfile:\n                tarfile.extractall(destination_path)\n            print(f'\\nDownloaded and uncompressed: {directory}')\n    except HTTPError as e:\n        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n        continue\n    except OSError as e:\n        print(f'Failed to load {download_url} to path {destination_path}')\n        continue\n\nprint('Data source import complete.')\n","metadata":{"id":"A5hYbStFZb_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#installing the dependencies\n!pip install -q accelerate\n!pip install -q transformers\n!pip install -q peft\n!pip install -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl\n!pip install huggingface_hub -q\n!pip install datasets -q\n!pip install nltk -q","metadata":{"id":"iVOrT-5vZcAM","outputId":"62b96a64-f162-45ab-a968-7c93f146d23c","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-31T14:07:23.157750Z","iopub.execute_input":"2024-05-31T14:07:23.158092Z","iopub.status.idle":"2024-05-31T14:09:18.725297Z","shell.execute_reply.started":"2024-05-31T14:07:23.158061Z","shell.execute_reply":"2024-05-31T14:09:18.724236Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"id":"oK7D7CN8ZcAR","outputId":"533d77a9-1a3a-4177-bd2c-7113b4a6974f","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-31T14:09:32.988374Z","iopub.execute_input":"2024-05-31T14:09:32.989238Z","iopub.status.idle":"2024-05-31T14:09:34.208433Z","shell.execute_reply.started":"2024-05-31T14:09:32.989196Z","shell.execute_reply":"2024-05-31T14:09:34.207577Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"nltk.data.path","metadata":{"execution":{"iopub.status.busy":"2024-05-31T11:53:02.662838Z","iopub.execute_input":"2024-05-31T11:53:02.663954Z","iopub.status.idle":"2024-05-31T11:53:02.672010Z","shell.execute_reply.started":"2024-05-31T11:53:02.663915Z","shell.execute_reply":"2024-05-31T11:53:02.670607Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['/root/nltk_data',\n '/usr/share/nltk_data',\n '/usr/local/share/nltk_data',\n '/usr/lib/nltk_data',\n '/usr/local/lib/nltk_data']"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig,\n    DataCollatorWithPadding\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"id":"_va8igNpZcAT","execution":{"iopub.status.busy":"2024-05-31T14:09:38.628222Z","iopub.execute_input":"2024-05-31T14:09:38.628786Z","iopub.status.idle":"2024-05-31T14:09:56.825349Z","shell.execute_reply.started":"2024-05-31T14:09:38.628752Z","shell.execute_reply":"2024-05-31T14:09:56.824377Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-31 14:09:47.850097: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-31 14:09:47.850192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-31 14:09:47.974999: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n\nfrom huggingface_hub import login\nlogin(token = hf_token)","metadata":{"id":"8H9CkZZGZcAV","outputId":"281a196e-a85e-434a-a9b9-b18da130e50a","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-31T14:10:10.642784Z","iopub.execute_input":"2024-05-31T14:10:10.644017Z","iopub.status.idle":"2024-05-31T14:10:10.999267Z","shell.execute_reply.started":"2024-05-31T14:10:10.643981Z","shell.execute_reply":"2024-05-31T14:10:10.998371Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n#torch.set_default_tensor_type(torch.cuda.FloatTensor)","metadata":{"id":"t1XnFdehZcAZ","execution":{"iopub.status.busy":"2024-05-31T14:10:19.773109Z","iopub.execute_input":"2024-05-31T14:10:19.773823Z","iopub.status.idle":"2024-05-31T14:10:19.778293Z","shell.execute_reply.started":"2024-05-31T14:10:19.773789Z","shell.execute_reply":"2024-05-31T14:10:19.777398Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = load_dataset(\"tdavidson/hate_speech_offensive\")\ndata = data['train']\ndata_df = data.to_pandas()","metadata":{"id":"bW1NeTT3ZcAc","execution":{"iopub.status.busy":"2024-05-31T14:10:23.858039Z","iopub.execute_input":"2024-05-31T14:10:23.858701Z","iopub.status.idle":"2024-05-31T14:10:28.997252Z","shell.execute_reply.started":"2024-05-31T14:10:23.858671Z","shell.execute_reply":"2024-05-31T14:10:28.996391Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8764e80cb184814aca1b88f57faeec1"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 1.63M/1.63M [00:01<00:00, 1.36MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/24783 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d00b7059e6ec4dec826470949c6161cd"}},"metadata":{}}]},{"cell_type":"code","source":"#data_df = data_df[:5000]","metadata":{"id":"yhMcmX1chfUc"},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load the stop words\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    # Lowercase the text\n    text = text.lower()\n    # Remove special characters and punctuation\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    # Tokenize the text\n    tokens = word_tokenize(text)\n    # Remove stop words and lemmatize the tokens\n    tokens = [word for word in tokens if word not in stop_words]\n    # Join the tokens back into a single string\n    text = ' '.join(tokens)\n    return text\n\n# Apply the preprocessing function to the 'text' column\ndata_df['tweet'] = data_df['tweet'].apply(preprocess_text)","metadata":{"id":"p0fWiiKMZcAf","execution":{"iopub.status.busy":"2024-05-31T14:10:34.222781Z","iopub.execute_input":"2024-05-31T14:10:34.223600Z","iopub.status.idle":"2024-05-31T14:10:39.012144Z","shell.execute_reply.started":"2024-05-31T14:10:34.223567Z","shell.execute_reply":"2024-05-31T14:10:39.011383Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:59:10.434843Z","iopub.execute_input":"2024-05-31T13:59:10.435207Z","iopub.status.idle":"2024-05-31T13:59:10.454410Z","shell.execute_reply.started":"2024-05-31T13:59:10.435178Z","shell.execute_reply":"2024-05-31T13:59:10.453541Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       count  hate_speech_count  offensive_language_count  neither_count  \\\n0          3                  0                         0              3   \n1          3                  0                         3              0   \n2          3                  0                         3              0   \n3          3                  0                         2              1   \n4          6                  0                         6              0   \n...      ...                ...                       ...            ...   \n24778      3                  0                         2              1   \n24779      3                  0                         1              2   \n24780      3                  0                         3              0   \n24781      6                  0                         6              0   \n24782      3                  0                         0              3   \n\n       class                                              tweet  \n0          2  rt mayasolovely woman shouldnt complain cleani...  \n1          1  rt mleew17 boy dats coldtyga dwn bad cuffin da...  \n2          1  rt urkindofbrand dawg rt 80sbaby4life ever fuc...  \n3          1           rt cganderson vivabased look like tranny  \n4          1  rt shenikaroberts shit hear might true might f...  \n...      ...                                                ...  \n24778      1  yous muthafin lie 8220lifeasking 20pearls core...  \n24779      2  youve gone broke wrong heart baby drove rednec...  \n24780      1  young buck wan na eat dat nigguh like aint fuc...  \n24781      1                  youu got wild bitches tellin lies  \n24782      2  ruffled ntac eileen dahlia beautiful color com...  \n\n[24783 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>hate_speech_count</th>\n      <th>offensive_language_count</th>\n      <th>neither_count</th>\n      <th>class</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>rt mayasolovely woman shouldnt complain cleani...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>rt mleew17 boy dats coldtyga dwn bad cuffin da...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>rt urkindofbrand dawg rt 80sbaby4life ever fuc...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>rt cganderson vivabased look like tranny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>rt shenikaroberts shit hear might true might f...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24778</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>yous muthafin lie 8220lifeasking 20pearls core...</td>\n    </tr>\n    <tr>\n      <th>24779</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>youve gone broke wrong heart baby drove rednec...</td>\n    </tr>\n    <tr>\n      <th>24780</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>young buck wan na eat dat nigguh like aint fuc...</td>\n    </tr>\n    <tr>\n      <th>24781</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>youu got wild bitches tellin lies</td>\n    </tr>\n    <tr>\n      <th>24782</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24783 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x = list(data_df['tweet'])\ny = list(data_df['class'])","metadata":{"id":"rYvG3SxvZcAh","execution":{"iopub.status.busy":"2024-05-31T14:10:58.303258Z","iopub.execute_input":"2024-05-31T14:10:58.303619Z","iopub.status.idle":"2024-05-31T14:10:58.315093Z","shell.execute_reply.started":"2024-05-31T14:10:58.303592Z","shell.execute_reply":"2024-05-31T14:10:58.314135Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )","metadata":{"id":"nAkr6OO3ZcAl","execution":{"iopub.status.busy":"2024-05-31T14:11:03.882608Z","iopub.execute_input":"2024-05-31T14:11:03.882963Z","iopub.status.idle":"2024-05-31T14:11:03.889044Z","shell.execute_reply.started":"2024-05-31T14:11:03.882935Z","shell.execute_reply":"2024-05-31T14:11:03.888177Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_name='microsoft/phi-2'\ndevice_map = {\"\": 0}\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,\n                                                       num_labels = 3,\n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)","metadata":{"id":"oQlPslv5ZcAm","outputId":"b4e71c4e-4756-4029-dd51-e452410b4c38","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["3a3b4f877ce545f6a7e666310344154c","6a864d63aed64087b938a7cd00163eee","6fb0cc835bd645cab97cd5e5b5d72061","901c0f84a73b4fb3bb8e3de1c80798f5","b2470f2a2191423cab3231c187a448bb","241bdc8e67664711b1f4f6fc704ec863","592837a5f3274a51a932a3ab329e5817","6df936f62eff46dc9663c8fb18fdec60","57b0be4c97eb48d4b8b20509dcbdae4d","3ae5582031e74436bd076dcafa2ed26a","9e62eac2ac6c48cba6a9987d93df135f"]},"execution":{"iopub.status.busy":"2024-05-31T14:11:07.578119Z","iopub.execute_input":"2024-05-31T14:11:07.578900Z","iopub.status.idle":"2024-05-31T14:11:27.726011Z","shell.execute_reply.started":"2024-05-31T14:11:07.578866Z","shell.execute_reply":"2024-05-31T14:11:27.725254Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c172b75f7ee24160ab94d43edcf361b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08019d8acb642abadcbf3d39e327d16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7e5b84f1b94533be689e9ac41377a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40461e78c76341379d47594958921421"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8033e9eeafbf49ae922342e32df5e251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"857185595e1540ca9953d32cbd72ca36"}},"metadata":{}},{"name":"stderr","text":"Some weights of PhiForSequenceClassification were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token\nmodel.config.pad_token_id = model.config.eos_token_id","metadata":{"id":"D6EQ3uiSZcAn","outputId":"e903dd08-6c47-4da6-97c6-358dd5e64e79","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-31T14:11:31.158387Z","iopub.execute_input":"2024-05-31T14:11:31.159095Z","iopub.status.idle":"2024-05-31T14:11:33.636103Z","shell.execute_reply.started":"2024-05-31T14:11:31.159054Z","shell.execute_reply":"2024-05-31T14:11:33.635222Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75f6ed495ef48a5bd0f1bfb09239fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54fd3203b4e74ff0886da6cf5c98e7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3db85a215da4a248dcd21dfc37579d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6009bfd200184b0596ff1d8c1756d571"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff958ee96fa7449688c3fd76e9f69c43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9492329a41a4d7daa0a248d301277c4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x,y, test_size = 0.3)\nx_train_tokenized = tokenizer(x_train, padding = True, truncation = True, max_length = 512 )\nx_val_tokenized = tokenizer(x_val, padding = True, truncation = True, max_length = 512 )","metadata":{"id":"ep2flZqcZcAi","execution":{"iopub.status.busy":"2024-05-31T14:11:40.238388Z","iopub.execute_input":"2024-05-31T14:11:40.239073Z","iopub.status.idle":"2024-05-31T14:11:47.117566Z","shell.execute_reply.started":"2024-05-31T14:11:40.239040Z","shell.execute_reply":"2024-05-31T14:11:47.116579Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Create torch dataset\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\ntrain_dataset = Dataset(x_train_tokenized, y_train)\nval_dataset = Dataset(x_val_tokenized, y_val)","metadata":{"id":"MarBGTAOZcAj","execution":{"iopub.status.busy":"2024-05-31T14:11:53.477891Z","iopub.execute_input":"2024-05-31T14:11:53.478655Z","iopub.status.idle":"2024-05-31T14:11:53.485468Z","shell.execute_reply.started":"2024-05-31T14:11:53.478620Z","shell.execute_reply":"2024-05-31T14:11:53.484548Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p):\n    print(type(p))\n    pred, labels = p\n    pred = np.argmax(pred, axis=1)\n\n    clf_rep = classification_report(y_true=labels, y_pred=pred)\n\n    return {\"classification_report\": clf_rep}","metadata":{"id":"QiFdvTf2ZcAk","execution":{"iopub.status.busy":"2024-05-31T14:11:56.868168Z","iopub.execute_input":"2024-05-31T14:11:56.869016Z","iopub.status.idle":"2024-05-31T14:11:56.873951Z","shell.execute_reply.started":"2024-05-31T14:11:56.868982Z","shell.execute_reply":"2024-05-31T14:11:56.872961Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\noriginal_model = prepare_model_for_kbit_training(model)\n\nconfig = LoraConfig(\n    r= 1, #Rank\n    lora_alpha=32,\n    target_modules=[\n        'q_proj',\n        'k_proj',\n        'v_proj',\n        'dense'\n    ],\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    task_type=\"SEQ_CLS\",\n)\n\n# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\noriginal_model.gradient_checkpointing_enable()\n\npeft_model = get_peft_model(original_model, config)","metadata":{"id":"u-BNAEQnZcAn","execution":{"iopub.status.busy":"2024-05-31T14:12:01.773274Z","iopub.execute_input":"2024-05-31T14:12:01.773651Z","iopub.status.idle":"2024-05-31T14:12:01.965253Z","shell.execute_reply.started":"2024-05-31T14:12:01.773621Z","shell.execute_reply":"2024-05-31T14:12:01.964495Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"peft_training_args = TrainingArguments(\n    output_dir = \"hate-phi\",\n    warmup_steps=1,\n    num_train_epochs = 1,\n    per_device_train_batch_size=32,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    optim=\"paged_adamw_8bit\",\n    logging_steps=25,\n    logging_dir=\"./logs\",\n    save_strategy=\"steps\",\n    save_steps=25,\n    evaluation_strategy=\"steps\",\n    eval_steps=25,\n    do_eval=True,\n    gradient_checkpointing=True,\n    report_to=\"none\",\n    overwrite_output_dir = 'True',\n    group_by_length=True,\n    \n)\n\npeft_model.config.use_cache = False\n\npeft_trainer = Trainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    args=peft_training_args,\n    data_collator= DataCollatorWithPadding(tokenizer),\n    compute_metrics = compute_metrics\n)","metadata":{"id":"2xTKIDd3ZcAo","outputId":"adc6e8a5-6c29-4eb5-939e-228be30d8309","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-05-31T14:12:40.663198Z","iopub.execute_input":"2024-05-31T14:12:40.664183Z","iopub.status.idle":"2024-05-31T14:12:40.707844Z","shell.execute_reply.started":"2024-05-31T14:12:40.664149Z","shell.execute_reply":"2024-05-31T14:12:40.706939Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"peft_trainer.train()","metadata":{"id":"H7a9bkyxZcAp","outputId":"2e24578b-8a69-4f57-faea-c416652b4326","colab":{"base_uri":"https://localhost:8080/","height":399},"execution":{"iopub.status.busy":"2024-05-31T14:12:44.573778Z","iopub.execute_input":"2024-05-31T14:12:44.574571Z","iopub.status.idle":"2024-05-31T19:15:04.113646Z","shell.execute_reply.started":"2024-05-31T14:12:44.574518Z","shell.execute_reply":"2024-05-31T19:15:04.112503Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [68/68 4:58:23, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Classification Report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.612400</td>\n      <td>0.369616</td>\n      <td>              precision    recall  f1-score   support\n\n           0       0.44      0.03      0.05       422\n           1       0.90      0.95      0.93      5753\n           2       0.74      0.79      0.76      1260\n\n    accuracy                           0.87      7435\n   macro avg       0.70      0.59      0.58      7435\nweighted avg       0.85      0.87      0.85      7435\n</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.326800</td>\n      <td>0.290043</td>\n      <td>              precision    recall  f1-score   support\n\n           0       0.50      0.16      0.25       422\n           1       0.92      0.96      0.94      5753\n           2       0.82      0.85      0.84      1260\n\n    accuracy                           0.89      7435\n   macro avg       0.75      0.66      0.67      7435\nweighted avg       0.88      0.89      0.88      7435\n</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"<class 'transformers.trainer_utils.EvalPrediction'>\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"<class 'transformers.trainer_utils.EvalPrediction'>\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=68, training_loss=0.4219165900174309, metrics={'train_runtime': 18136.4921, 'train_samples_per_second': 0.957, 'train_steps_per_second': 0.004, 'total_flos': 5.399469532151808e+16, 'train_loss': 0.4219165900174309, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"peft_trainer.evaluate()","metadata":{"id":"-XZe7AulZcAq","execution":{"iopub.status.busy":"2024-05-31T19:15:28.032294Z","iopub.execute_input":"2024-05-31T19:15:28.033070Z","iopub.status.idle":"2024-05-31T19:35:38.134796Z","shell.execute_reply.started":"2024-05-31T19:15:28.033038Z","shell.execute_reply":"2024-05-31T19:35:38.133737Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='465' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [465/465 20:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"<class 'transformers.trainer_utils.EvalPrediction'>\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.2798629105091095,\n 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.50      0.23      0.32       422\\n           1       0.92      0.96      0.94      5753\\n           2       0.84      0.85      0.85      1260\\n\\n    accuracy                           0.90      7435\\n   macro avg       0.75      0.68      0.70      7435\\nweighted avg       0.89      0.90      0.89      7435\\n',\n 'eval_runtime': 1210.0957,\n 'eval_samples_per_second': 6.144,\n 'eval_steps_per_second': 0.384,\n 'epoch': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"#Phi-2 metrics\n'''\neval_classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.50      0.23      0.32       422\\n           1       0.92      0.96      0.94      5753\\n           2       0.84      0.85      0.85      1260\\n\\n    accuracy                           0.90      7435\\n   macro avg       0.75      0.68      0.70      7435\\nweighted avg       0.89      0.90      0.89      7435\\n',\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_trainer.push_to_hub(\"HatePhi-2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T19:38:59.524934Z","iopub.execute_input":"2024-05-31T19:38:59.525313Z","iopub.status.idle":"2024-05-31T19:39:02.025709Z","shell.execute_reply.started":"2024-05-31T19:38:59.525281Z","shell.execute_reply":"2024-05-31T19:39:02.024908Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/2.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df0b83410fee40cb850f0c9704d7ef3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3886be0943144787aa9fe6b9c49d1046"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"984a6b2f308c4645a8753b2b52049797"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datafreak/hate-phi/commit/a6ad6ce2bc2847d98d539573680891b47c05ab60', commit_message='HatePhi-2', commit_description='', oid='a6ad6ce2bc2847d98d539573680891b47c05ab60', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"total_train_samples = 17000  # Replace with your dataset size\nsteps_per_epoch = total_train_samples // (peft_training_args.per_device_train_batch_size * peft_training_args.gradient_accumulation_steps)\ntarget_training_steps = steps_per_epoch * peft_training_args.num_train_epochs  # 2 epochs","metadata":{"id":"P9XprhiAj_xJ"},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"target_training_steps","metadata":{"id":"_YftaVm0kIJg","outputId":"3c00e115-19b9-4b8d-d350-a4bfafd777c2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":["264"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"SgEe9CZlkKq9"},"execution_count":null,"outputs":[]}]}